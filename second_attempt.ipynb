{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Read CSV\n",
    "movies = pd.read_csv('movies.csv',sep=';',encoding = \"utf-8\",header=None)\n",
    "predictions = pd.read_csv('predictions.csv',sep=';',header=None)\n",
    "users = pd.read_csv('users.csv',sep=';',header=None)\n",
    "ratings = pd.read_csv('ratings.csv',sep=';',header=None)\n",
    "\n",
    "# Add column names\n",
    "movies.columns = ['movieId','movieYear','movieTitle']\n",
    "predictions.columns = ['userId','movieId']\n",
    "users.columns = ['userId','userGender','userAge','userProfession']\n",
    "ratings.columns = ['userId','movieId','rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_rounder(number: int) -> int:\n",
    "    if (number < 1):\n",
    "        return 1\n",
    "    elif (number > 5):\n",
    "        return 5\n",
    "    else:\n",
    "        return int(round(number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241471</th>\n",
       "      <td>5896</td>\n",
       "      <td>1474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817851</th>\n",
       "      <td>880</td>\n",
       "      <td>1509</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853538</th>\n",
       "      <td>2391</td>\n",
       "      <td>2100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30530</th>\n",
       "      <td>4227</td>\n",
       "      <td>786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876595</th>\n",
       "      <td>1778</td>\n",
       "      <td>1353</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "241471    5896     1474       1\n",
       "817851     880     1509       5\n",
       "853538    2391     2100       2\n",
       "30530     4227      786       1\n",
       "876595    1778     1353       3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train-test split |\n",
    "# We now use the whole data for training and just consider training loss so we don't need to split, I leave this here for clarity sake. \n",
    "ratings_train = ratings.sample(frac=0.8, random_state=42)\n",
    "ratings_validation = ratings.drop(ratings_train.index).sample(frac=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ CSV into NP ARR \n",
    "# Don't ask me why the PANDAS way doesn't work it automatically gets rid of 10 movies or somehting @Minh\n",
    "# So we have to do it the old fashioned way just by iterating, takes about 20s\n",
    "\n",
    "def create_np_matrix(number_of_users, number_of_movies, appropriate_ratings_DF):\n",
    "    np_matrix = np.zeros((number_of_users,number_of_movies))\n",
    "    for index, row in appropriate_ratings_DF.iterrows():\n",
    "        cur_user_id = row['userId']\n",
    "        cur_movie_id = row['movieId']\n",
    "        cur_rating = row['rating']\n",
    "        np_matrix[cur_user_id - 1,cur_movie_id - 1] = int(cur_rating)\n",
    "    \n",
    "    return np_matrix\n",
    "\n",
    "my_matrix = create_np_matrix(len(users), len(movies), ratings)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_sgd(matrix, K=5, epochs=11, alpha=0.0001, beta=0.02, error_threshold=0.905):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        matrix: user-item training matrix\n",
    "        K: Number of latent factors\n",
    "        epochs: Number of epochs 4 SGD\n",
    "        a: Learning Rate 4 SGD\n",
    "        beta: Regularization term 4 SGD\n",
    "        error_threshold: Error required for an early stop\n",
    "\n",
    "    Returns:\n",
    "        The Decomposed Matrices\n",
    "    \"\"\"    \n",
    "    num_users = len(matrix)\n",
    "    num_movies = len(matrix[0])\n",
    "\n",
    "    assert num_users == len(users)\n",
    "    assert num_movies == len(movies)\n",
    "\n",
    "    non_zero_entries = np.argwhere(matrix>0)\n",
    "\n",
    "    # Initialise decomposed matrices with random nums\n",
    "    P = np.random.rand(num_users,K)\n",
    "    Q = np.random.rand(num_movies,K)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        entries_in_epoch_condition_holds_test = 0\n",
    "        for entry in non_zero_entries:\n",
    "            i = entry[0]\n",
    "            j = entry[1]\n",
    "            if matrix[i][j] > 0:\n",
    "                entries_in_epoch_condition_holds_test +=1\n",
    "\n",
    "                # self-note: reconstruct by: np.dot(P[i,:],Q[j,:]), \n",
    "                # we dot the embeddings together, can be viewed as a matrix-vector product aswell \n",
    "                cur_error = matrix[i][j] - np.dot(P[i,:],Q[j,:]) \n",
    "                \n",
    "\n",
    "                #SGD\n",
    "\n",
    "                for k in range(K):\n",
    "                    P[i][k] = P[i][k] + alpha * (2 * cur_error * Q[j][k] - 2 * beta * P[i][k])\n",
    "                    Q[j][k] = Q[j][k] + alpha * (2 * cur_error * P[i][k] - 2 * beta * Q[j][k])\n",
    "\n",
    "        assert entries_in_epoch_condition_holds_test == len(ratings)\n",
    "\n",
    "        acc_error = 0\n",
    "        count = 0\n",
    "\n",
    "        for entry in non_zero_entries:\n",
    "            i = entry[0]\n",
    "            j = entry[1]\n",
    "\n",
    "            cur_rating = matrix[i][j]\n",
    "            acc_error = acc_error + (cur_rating - np.dot(P[i,:],Q[j,:])) * (cur_rating - np.dot(P[i,:],Q[j,:]))\n",
    "            for k in range(K):\n",
    "                #factor in error for regularization of latent factors \n",
    "                acc_error = acc_error + (beta/2) * (P[i][k] * P[i][k] + Q[j][k] * Q[j][k])\n",
    "            count += 1\n",
    "\n",
    "        \"\"\"\n",
    "        We don't consider validation loss anymore, since we use all the data, SGD doesn't perform well w/ less data.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # for index, row in validation_set.iterrows():\n",
    "        #     cur_user_id = row['userId']\n",
    "        #     cur_movie_id = row['movieId']\n",
    "        #     cur_rating = row['rating']\n",
    "        #     # my_matrix[cur_user_id - 1,cur_movie_id - 1] = int(cur_rating)\n",
    "        #     i = cur_user_id - 1\n",
    "        #     j = cur_movie_id - 1\n",
    "        #     acc_error = acc_error + (cur_rating - np.dot(P[i,:],Q[j,:])) * (cur_rating - np.dot(P[i,:],Q[j,:]))\n",
    "        #     for k in range(K):\n",
    "        #         #factor in error for regularization\n",
    "        #         acc_error = acc_error + (beta/2) * (P[i][k] * P[i][k] + Q[j][k] * Q[j][k])\n",
    "        #     count += 1\n",
    "\n",
    "        if (count==0):\n",
    "            print(\"Continued on Epoch # INVALID DATA OR ALGORITHM BROKEN\" + str(epoch + 1))\n",
    "            continue\n",
    "\n",
    "        rmse = np.sqrt(acc_error / count)\n",
    "        if (epoch % 5 == 0):\n",
    "            print(\"EPOCH #\" + str(epoch) + \" Training Error (not validation): \" + str(rmse))\n",
    "            \n",
    "        if rmse < error_threshold:\n",
    "            break\n",
    "\n",
    "    return P, Q\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 Training Error (not validation): 2.073213471048759\n",
      "EPOCH #5 Training Error (not validation): 1.2324482370698204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m p_arr, q_arr \u001b[39m=\u001b[39m mf_sgd(my_matrix, error_threshold\u001b[39m=\u001b[39;49m\u001b[39m0.88\u001b[39;49m)\n",
      "\u001b[1;32m/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb Cell 6\u001b[0m in \u001b[0;36mmf_sgd\u001b[0;34m(matrix, K, epochs, alpha, beta, error_threshold)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(K):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m             P[i][k] \u001b[39m=\u001b[39m P[i][k] \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m cur_error \u001b[39m*\u001b[39m Q[j][k] \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m beta \u001b[39m*\u001b[39m P[i][k])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m             Q[j][k] \u001b[39m=\u001b[39m Q[j][k] \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m cur_error \u001b[39m*\u001b[39m P[i][k] \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m beta \u001b[39m*\u001b[39m Q[j][k])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39massert\u001b[39;00m entries_in_epoch_condition_holds_test \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(ratings)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/henry/MLProjects/DMProjects/cse2525-reccommender-systems-challenge/second_attempt.ipynb#W5sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m acc_error \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "p_arr, q_arr = mf_sgd(my_matrix, error_threshold=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.34127429 2.7637479  2.55651208 ... 2.40075143 1.96865865 2.99586454]\n",
      " [3.6730696  2.76892708 2.78450855 ... 2.40077239 2.15570131 3.20970408]\n",
      " [3.42669967 2.59752878 2.38853633 ... 2.56925243 1.97280817 2.92722212]\n",
      " ...\n",
      " [2.74582391 1.80652757 2.01862944 ... 1.79087162 1.34931832 2.19197826]\n",
      " [3.83990581 2.52644848 2.38239603 ... 2.54302212 1.81380701 2.831786  ]\n",
      " [4.11389816 3.26033626 3.08530657 ... 2.8052905  2.4673001  3.64557349]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6587257135079283"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE HERE\n",
    "final_result = np.dot(p_arr, q_arr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = []\n",
    "\n",
    "# Write to File\n",
    "for index, row in predictions.iterrows():\n",
    "    cur_user_id = row['userId']\n",
    "    cur_movie_id = row['movieId']\n",
    "\n",
    "    csv_data.append([index + 1, number_rounder(final_result[cur_user_id - 1, cur_movie_id - 1])])\n",
    "\n",
    "    \n",
    "with open('guess_no_lib.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('temp_result',final_result)\n",
    "# test = np.load('temp_result.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfe86cd4d92790ecf8ae6b2e8147170aa06d4b6c18edb6e0ff4918ea95805036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
